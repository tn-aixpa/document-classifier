{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d86fdf-bbb8-4476-b24f-b06e75c00cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import digitalhub as dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0a415b-4098-4e76-82ac-d1c34f4242d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = dh.get_or_create_project('family-audit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ba62ca-ade1-4b3e-8418-7e251d05dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "new_folder = 'src'\n",
    "if not os.path.exists(new_folder):\n",
    "    os.makedirs(new_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5032e28-732d-400e-843f-74b5fbb9b269",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj.log_model(\n",
    "        name='family_audit_model',\n",
    "        kind=\"huggingface\",\n",
    "        base_model=\"dbmdz/bert-base-italian-xxl-cased\",\n",
    "        # metrics=metrics,\n",
    "        source='tuned_model',\n",
    "    )             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73ec4a0-e227-44ff-8866-c85290104208",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"src/serve.py\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torchmetrics.classification import MulticlassF1Score, Accuracy\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoModel\n",
    "from transformers import PreTrainedModel\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "class BertForSentenceClassification(PreTrainedModel):\n",
    "\n",
    "    \"\"\"\n",
    "    BERT architecture is intended to be from \"dbmdz/bert-base-italian-xxl-cased\"\n",
    "    but other models can be tried.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, config, model_name, num_labels, class_weights=None):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        self.class_weights = class_weights\n",
    "        self.accuracy = Accuracy(num_classes=num_labels, task='multiclass')\n",
    "        self.f1 = MulticlassF1Score(num_classes=num_labels, average='micro') # changed weight\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = self.classifier(outputs.last_hidden_state[:, 0, :])\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "\n",
    "            loss_fct = nn.CrossEntropyLoss(label_smoothing=0.1) #,weight=self.class_weights\n",
    "            loss = loss_fct(logits, labels)\n",
    "\n",
    "            f1_score = self.f1(logits.argmax(dim=1), labels)\n",
    "            accuracy_score = self.accuracy(logits.argmax(dim=1), labels)\n",
    "\n",
    "        return SequenceClassifierOutput(loss=loss, logits=logits)\n",
    "\n",
    "def init(context):\n",
    "    model_name = \"family_audit_model\"\n",
    "   \n",
    "    model = context.project.get_model(model_name)\n",
    "    local_path_model = model.download(overwrite=True)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(local_path_model)\n",
    "    config = AutoConfig.from_pretrained(local_path_model)\n",
    "    \n",
    "    mm = BertForSentenceClassification.from_pretrained(\n",
    "        local_path_model,\n",
    "        config=config,\n",
    "        model_name=\"dbmdz/bert-base-italian-xxl-cased\",\n",
    "        num_labels=config.num_labels\n",
    "    ) \n",
    "\n",
    "    label_mapping = {\n",
    "        0: 0,\n",
    "        1: 2,\n",
    "        2: 4,\n",
    "        3: 7,\n",
    "        4: 8,\n",
    "        5: 10,\t\n",
    "        6: 11,\n",
    "        7: 15,\n",
    "        8: 16,\n",
    "        9: 17,\n",
    "        10: 20,\n",
    "        11: 22,\n",
    "        12: 25,\n",
    "        13: 27,\n",
    "        14: 28,\n",
    "        15: 29,\n",
    "        16: 36,\n",
    "        17: 39,\n",
    "        18: 45,\n",
    "        19: 50,\n",
    "        20: 51,\n",
    "        21: 53,\n",
    "        22: 54,\n",
    "        23: 55,\n",
    "        24: 56,\n",
    "        25: 57,\n",
    "        26: 61,\n",
    "        27: 62,\n",
    "        28: 63,\n",
    "        29: 64,\n",
    "        30: 65,\n",
    "        31: 67,\n",
    "        32: 68,\n",
    "        33: 69,\n",
    "        34: 72,\n",
    "        35: 74,\n",
    "        36: 81,\n",
    "        37: 88,\n",
    "        38: 89,\n",
    "        39: 91,\n",
    "        40: 96,\n",
    "        41: 102,\n",
    "        42: 107,\n",
    "        43: 108,\n",
    "        44: 109,\n",
    "        45: 112,\n",
    "        46: 113,\n",
    "        47: 115,\n",
    "        48: 116,\n",
    "        49: 119,\n",
    "        50: 120,\n",
    "        51: 126,\n",
    "        52: 130,\n",
    "        53: 133,\n",
    "        54: 134,\n",
    "        55: 195\n",
    "    }\n",
    "\n",
    "    setattr(context, \"model\", mm)\n",
    "    setattr(context, \"tokenizer\", tokenizer)\n",
    "    setattr(context, \"label_mapping\", label_mapping)\n",
    "\n",
    "def serve(context, event):\n",
    "\n",
    "    context.logger.info(f\"Received event: {event}\")\n",
    "    \n",
    "    if isinstance(event.body, bytes):\n",
    "        body = json.loads(event.body)\n",
    "    else:\n",
    "        body = event.body\n",
    "        \n",
    "    inference_input = body[\"inference_input\"]\n",
    "    \n",
    "    pdf = pd.DataFrame(inference_input, index=[0])\n",
    "    k = int(pdf['k'])\n",
    "    inputs = context.tokenizer(str(pdf['text']), return_tensors=\"pt\", truncation=True, padding=True, return_token_type_ids=False)\n",
    "    context.logger.info(f\"k received: {k}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = context.model(**inputs).logits\n",
    "        sigmoid = torch.nn.Sigmoid()\n",
    "        probs = sigmoid(logits.squeeze().cpu())\n",
    "        indices_above_threshold = (probs >= 0.6).nonzero(as_tuple=True)[0]\n",
    "        probs_above_threshold = probs[indices_above_threshold]\n",
    "        sorted_indices = probs_above_threshold.argsort(descending=True)\n",
    "        top_k_indices = indices_above_threshold[sorted_indices][:k]\n",
    "        result = [context.label_mapping[int(idx)] + 1 for idx in top_k_indices]\n",
    "        context.logger.info(f\"result: {result}\")\n",
    "        \n",
    "    # Convert the result to a json string.\n",
    "    jsonstr = '{\"results\": ' + str(list(result)) + '}'\n",
    " \n",
    "    return json.loads(jsonstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a2cbcd-8ae9-4bea-83ff-1d9b307f7f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = proj.new_function(\n",
    "    name=\"serve_model\",\n",
    "    kind=\"python\",\n",
    "    python_version=\"PYTHON3_10\",\n",
    "    source={\n",
    "        \"source\": \"src/serve.py\",\n",
    "        \"handler\": \"serve\",\n",
    "        \"init_function\": \"init\"},\n",
    "    requirements=[\"numpy<2\", \"pandas==2.1.4\",\"transformer_engine==1.12.0\", \"transformer_engine_cu12==1.12.0\", \"transformers==4.46.3\", \"torch==2.5.1\", \"torchmetrics==1.6.0\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22738d9e-60ce-4774-819f-982e044ef82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "serve_run = func.run(\n",
    "    action=\"serve\",\n",
    "    volumes=[{ \n",
    "            \"volume_type\": \"persistent_volume_claim\", \n",
    "            \"name\": \"family-audit\", \n",
    "            \"mount_path\": \"/files\", \n",
    "            \"spec\": { \"claim_name\": \"family-audit\" }\n",
    "        }]\n",
    ") #, resources = {\"mem\":{\"requests\": \"32Gi\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b43600c-ccab-4fe1-947a-31d8ba7bcfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "serve_run.refresh().status.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5238652d-50d0-416e-a22f-9d0204e5355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = serve_run.refresh().status.service\n",
    "service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9d387-1970-4828-afaa-4a2e8e7e6103",
   "metadata": {},
   "outputs": [],
   "source": [
    "serve_run = proj.get_run(identifier='41c65ab406f8442f9ff9b763a36151d8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1190f2-12b6-4957-a5e0-3b44af6271e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"text\": 'famiglia wifi ', \"k\": 1}\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b74b58-1470-4fa3-9f47-fa116a523531",
   "metadata": {},
   "outputs": [],
   "source": [
    "serve_run.invoke(json={\"inference_input\": inputs}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b090cf1-7f37-4095-8f9e-1d6db34dfbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "SERVICE_URL = serve_run.refresh().status.to_dict()[\"service\"][\"url\"]\n",
    "\n",
    "with requests.post(f'http://{SERVICE_URL}', json={\"inference_input\":inputs}) as r:\n",
    "    res = r.content\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
